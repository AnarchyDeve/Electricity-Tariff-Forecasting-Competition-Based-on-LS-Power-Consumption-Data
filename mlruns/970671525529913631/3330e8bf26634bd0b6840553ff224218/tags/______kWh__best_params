{'n_layers': 2, 'units': 128, 'dropout': 0.4, 'n_heads': 8, 'seq_len': 12, 'lr': 0.0005265598655192859, 'batch_size': 16, 'epochs': 30}